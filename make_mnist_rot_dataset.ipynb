{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "make_mnist_rot_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "bDuam-Y8N7Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os, shutil\n",
        "# shutil.copyfile('__notebook_source__.ipynb', 'make_mnist_rot_dataset')\n",
        "# os.listdir()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-08T05:42:51.231807Z",
          "iopub.execute_input": "2022-05-08T05:42:51.232112Z",
          "iopub.status.idle": "2022-05-08T05:42:51.239892Z",
          "shell.execute_reply.started": "2022-05-08T05:42:51.232068Z",
          "shell.execute_reply": "2022-05-08T05:42:51.238972Z"
        },
        "trusted": true,
        "id": "nl-hkYyXN7Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-08T05:42:03.421837Z",
          "iopub.execute_input": "2022-05-08T05:42:03.422114Z",
          "iopub.status.idle": "2022-05-08T05:42:03.427992Z",
          "shell.execute_reply.started": "2022-05-08T05:42:03.422085Z",
          "shell.execute_reply": "2022-05-08T05:42:03.427237Z"
        },
        "trusted": true,
        "id": "U39OMtlsN7Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils.py"
      ],
      "metadata": {
        "id": "yvW6idoZN7Af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function\n",
        "from scipy.linalg import expm, norm\n",
        "import collections\n",
        "import itertools\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "\n",
        "def ntuple(n):\n",
        "    \"\"\" Ensure that input has the correct number of elements \"\"\"\n",
        "    def parse(x):\n",
        "        if isinstance(x, collections.Iterable):\n",
        "            return x\n",
        "        return tuple(itertools.repeat(x, n))\n",
        "    return parse\n",
        "\n",
        "def getGrid(siz):\n",
        "    \"\"\" Returns grid with coordinates from -siz[0]/2 : siz[0]/2, -siz[1]/2 : siz[1]/2, ....\"\"\"\n",
        "    space = [np.linspace( -(N/2), (N/2), N ) for N in siz]\n",
        "    mesh = np.meshgrid( *space, indexing='ij' )\n",
        "    mesh = [np.expand_dims( ax.ravel(), 0) for ax in mesh]\n",
        "\n",
        "    return np.concatenate(mesh)\n",
        "\n",
        "def rotate_grid_2D(grid, theta):\n",
        "    \"\"\" Rotate grid \"\"\"\n",
        "    theta = np.deg2rad(theta)\n",
        "\n",
        "    x0 = grid[0, :] * np.cos(theta) - grid[1, :] * np.sin(theta)\n",
        "    x1 = grid[0, :] * np.sin(theta) + grid[1, :] * np.cos(theta)\n",
        "\n",
        "    grid[0, :] = x0\n",
        "    grid[1, :] = x1\n",
        "    return grid\n",
        "\n",
        "def rotate_grid_3D(theta, axis, grid):\n",
        "    \"\"\" Rotate grid \"\"\"\n",
        "    theta = np.deg2rad(theta)\n",
        "    axis = np.array(axis)\n",
        "    rot_mat = expm(np.cross(np.eye(3), axis / norm(axis) * theta))\n",
        "    rot_mat  =np.expand_dims(rot_mat,2)\n",
        "    grid = np.transpose( np.expand_dims(grid,2), [0,2,1])\n",
        "\n",
        "    return np.einsum('ijk,jik->ik',rot_mat,grid)\n",
        "\n",
        "\n",
        "def get_filter_rotation_transforms(kernel_dims, angles):\n",
        "    \"\"\" Return the interpolation variables needed to transform a filter by a given number of degrees \"\"\"\n",
        "\n",
        "    dim = len(kernel_dims)\n",
        "\n",
        "    # Make grid (centered around filter-center)\n",
        "    grid = getGrid(kernel_dims)\n",
        "\n",
        "    # Rotate grid\n",
        "    if dim == 2:\n",
        "        grid = rotate_grid_2D(grid, angles)\n",
        "    elif dim == 3:\n",
        "        grid = rotate_grid_3D(angles[0], [1, 0, 0], grid)\n",
        "        grid = rotate_grid_3D(angles[1], [0, 0, 1], grid)\n",
        "\n",
        "\n",
        "    # Radius of filter\n",
        "    radius = np.min((np.array(kernel_dims)-1) / 2.)\n",
        "\n",
        "    #Mask out samples outside circle\n",
        "    radius = np.expand_dims(radius,-1)\n",
        "    dist_to_center = np.sqrt(np.sum(grid**2,axis=0))\n",
        "    mask = dist_to_center>=radius+.0001\n",
        "    mask = 1-mask\n",
        "\n",
        "    # Move grid to center\n",
        "    grid += radius\n",
        "\n",
        "    return compute_interpolation_grids(grid, kernel_dims, mask)\n",
        "\n",
        "def compute_interpolation_grids(grid, kernel_dims, mask):\n",
        "\n",
        "    #######################################################\n",
        "    # The following part is part of nd-linear interpolation\n",
        "\n",
        "    #Add a small eps to grid so that floor and ceil operations become more stable\n",
        "    grid += 0.000000001\n",
        "\n",
        "    # Make list where each element represents a dimension\n",
        "    grid = [grid[i, :] for i in range(grid.shape[0])]\n",
        "\n",
        "    # Get left and right index (integers)\n",
        "    inds_0 = [ind.astype(np.integer) for ind in grid]\n",
        "    inds_1 = [ind + 1 for ind in inds_0]\n",
        "\n",
        "    # Get weights\n",
        "    weights = [float_ind - int_ind for float_ind, int_ind in zip(grid, inds_0)]\n",
        "\n",
        "    # Special case for when ind_1 == size (while ind_0 == siz)\n",
        "    # In that case we select ind_0\n",
        "    ind_1_out_of_bounds = np.logical_or.reduce([ind == siz for ind, siz in zip(inds_1, kernel_dims)])\n",
        "    for i in range(len(inds_1)):\n",
        "        inds_1[i][ind_1_out_of_bounds] = 0\n",
        "\n",
        "\n",
        "    # Get samples that are out of bounds or outside mask\n",
        "    inds_out_of_bounds = np.logical_or.reduce([ind < 0 for ind in itertools.chain(inds_0, inds_1)] + \\\n",
        "                                              [ind >= siz for ind, siz in zip(inds_0, kernel_dims)] + \\\n",
        "                                              [ind >= siz for ind, siz in zip(inds_1, kernel_dims)] +\n",
        "                                              (1-mask).astype('bool')\n",
        "                                              )\n",
        "\n",
        "\n",
        "    # Set these samples to zero get data from upper-left-corner (which will be put to zero)\n",
        "    for i in range(len(inds_0)):\n",
        "        inds_0[i][inds_out_of_bounds] = 0\n",
        "        inds_1[i][inds_out_of_bounds] = 0\n",
        "\n",
        "    #Reshape\n",
        "    inds_0 = [np.reshape(ind,[1,1]+kernel_dims) for ind in inds_0]\n",
        "    inds_1 = [np.reshape(ind,[1,1]+kernel_dims) for ind in inds_1]\n",
        "    weights = [np.reshape(weight,[1,1]+kernel_dims)for weight in weights]\n",
        "\n",
        "    #Make pytorch-tensors of the interpolation variables\n",
        "    inds_0 = [Variable(torch.LongTensor(ind)) for ind in inds_0]\n",
        "    inds_1 = [Variable(torch.LongTensor(ind)) for ind in inds_1]\n",
        "    weights = [Variable(torch.FloatTensor(weight)) for weight in weights]\n",
        "\n",
        "    #Make mask pytorch tensor\n",
        "    mask = mask.reshape(kernel_dims)\n",
        "    mask = mask.astype('float32')\n",
        "    mask = np.expand_dims(mask, 0)\n",
        "    mask = np.expand_dims(mask, 0)\n",
        "    mask = torch.FloatTensor(mask)\n",
        "\n",
        "    # Uncomment for nearest interpolation (for debugging)\n",
        "    #inds_1 = [ind*0 for ind in inds_1]\n",
        "    #weights  = [weight*0 for weight in weights]\n",
        "\n",
        "    return inds_0, inds_1, weights, mask\n",
        "\n",
        "def apply_transform(filter, interp_vars, filters_size, old_bilinear_interpolation=True):\n",
        "    \"\"\" Apply a transform specified by the interpolation_variables to a filter \"\"\"\n",
        "\n",
        "    dim = 2 if len(filter.size())==4 else 3\n",
        "\n",
        "    if dim == 2:\n",
        "\n",
        "\n",
        "        if old_bilinear_interpolation:\n",
        "            [x0_0, x1_0], [x0_1, x1_1], [w0, w1] = interp_vars\n",
        "            rotated_filter = (filter[:, :, x0_0, x1_0] * (1 - w0) * (1 - w1) +\n",
        "                          filter[:, :, x0_1, x1_0] * w0 * (1 - w1) +\n",
        "                          filter[:, :, x0_0, x1_1] * (1 - w0) * w1 +\n",
        "                          filter[:, :, x0_1, x1_1] * w0 * w1)\n",
        "        else:\n",
        "\n",
        "            # Expand dimmentions to fit filter\n",
        "            interp_vars = [[inner_el.expand_as(filter) for inner_el in outer_el] for outer_el in interp_vars]\n",
        "\n",
        "            [x0_0, x1_0], [x0_1, x1_1], [w0, w1] = interp_vars\n",
        "\n",
        "            a = torch.gather(torch.gather(filter, 2, x0_0), 3, x1_0) * (1 - w0) * (1 - w1)\n",
        "            b = torch.gather(torch.gather(filter, 2, x0_1), 3, x1_0)* w0 * (1 - w1)\n",
        "            c = torch.gather(torch.gather(filter, 2, x0_0), 3, x1_1)* (1 - w0) * w1\n",
        "            d = torch.gather(torch.gather(filter, 2, x0_1), 3, x1_1)* w0 * w1\n",
        "            rotated_filter = a+b+c+d\n",
        "\n",
        "        rotated_filter = rotated_filter.view(filter.size()[0],filter.size()[1],filters_size[0],filters_size[1])\n",
        "\n",
        "    elif dim == 3:\n",
        "        [x0_0, x1_0, x2_0], [x0_1, x1_1, x2_1], [w0, w1, w2] = interp_vars\n",
        "\n",
        "        rotated_filter = (filter[x0_0, x1_0, x2_0] * (1 - w0) * (1 - w1)* (1 - w2) +\n",
        "                          filter[x0_1, x1_0, x2_0] * w0       * (1 - w1)* (1 - w2) +\n",
        "                          filter[x0_0, x1_1, x2_0] * (1 - w0) * w1      * (1 - w2) +\n",
        "                          filter[x0_1, x1_1, x2_0] * w0       * w1      * (1 - w2) +\n",
        "                          filter[x0_0, x1_0, x2_1] * (1 - w0) * (1 - w1)* w2 +\n",
        "                          filter[x0_1, x1_0, x2_1] * w0       * (1 - w1)* w2 +\n",
        "                          filter[x0_0, x1_1, x2_1] * (1 - w0) * w1      * w2 +\n",
        "                          filter[x0_1, x1_1, x2_1] * w0       * w1      * w2)\n",
        "\n",
        "        rotated_filter = rotated_filter.view(filter.size()[0], filter.size()[1], filters_size[0], filters_size[1], filters_size[2])\n",
        "\n",
        "    return rotated_filter\n",
        "\n",
        "print(\"unitls.py is ok!!!\")\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     \"\"\" Test rotation of filter \"\"\"\n",
        "#     import torch.nn as nn\n",
        "#     from torch.nn import functional as F\n",
        "#     from torch.nn.parameter import Parameter\n",
        "#     import math\n",
        "#     from utils import *\n",
        "\n",
        "#     ks = [9,9] #Kernel size\n",
        "#     angle = 45\n",
        "#     interp_vars = get_filter_rotation_transforms(ks, angle)\n",
        "\n",
        "#     w = Variable(torch.ones([1,1]+ks))\n",
        "#     #w[:,:,4,:] = 5\n",
        "#     w[:, :, :, 4] = 5\n",
        "#     #w[:,:,0,0] = -1\n",
        "\n",
        "\n",
        "#     print(w)\n",
        "#     for angle in [0,90,45,180,65,10]:\n",
        "#         print(angle,'degrees')\n",
        "#         print(apply_transform(w, get_filter_rotation_transforms(ks, angle)[:-1], ks,old_bilinear_interpolation=True) * Variable(get_filter_rotation_transforms(ks, angle)[-1]))\n",
        "#         print('Difference', torch.sum(apply_transform(w, get_filter_rotation_transforms(ks, angle)[:-1], ks,old_bilinear_interpolation=False) * Variable( get_filter_rotation_transforms(ks, angle)[-1]) - apply_transform(w, get_filter_rotation_transforms(ks, angle)[:-1], ks,old_bilinear_interpolation=True) * Variable(get_filter_rotation_transforms(ks, angle)[-1])))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-08T03:47:03.108565Z",
          "iopub.execute_input": "2022-05-08T03:47:03.109144Z",
          "iopub.status.idle": "2022-05-08T03:47:04.544499Z",
          "shell.execute_reply.started": "2022-05-08T03:47:03.109058Z",
          "shell.execute_reply": "2022-05-08T03:47:04.543909Z"
        },
        "trusted": true,
        "id": "4yBeq0vZN7Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mnist.py"
      ],
      "metadata": {
        "id": "H2drUr--N7Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# import scipy.misc\n",
        "import sys\n",
        "import os\n",
        "# sys.path.append('../')\n",
        "print(os.getcwd())\n",
        "# from utils import getGrid, rotate_grid_2D\n",
        "from imageio import imread\n",
        "\n",
        "\n",
        "def loadMnist(mode):\n",
        "    print('Loading MNIST', mode, 'images')\n",
        "    # Mode = 'train'/'test\n",
        "    mnist_folder = './'\n",
        "\n",
        "    with open(mnist_folder + mode + '-labels.csv') as f:\n",
        "        path_and_labels = f.readlines()\n",
        "\n",
        "    samples = []\n",
        "    for entry in path_and_labels:\n",
        "        path = entry.split(',')[0]\n",
        "        label = int(entry.split(',')[1])\n",
        "        img = imread(mnist_folder + path)\n",
        "        samples.append([img, label])\n",
        "    return samples\n",
        "\n",
        "\n",
        "def linear_interpolation_2D(input_array, indices, outside_val=0, boundary_correction=True):\n",
        "    # http://stackoverflow.com/questions/6427276/3d-interpolation-of-numpy-arrays-without-scipy\n",
        "    output = np.empty(indices[0].shape)\n",
        "    ind_0 = indices[0, :]\n",
        "    ind_1 = indices[1, :]\n",
        "\n",
        "    N0, N1 = input_array.shape\n",
        "\n",
        "    x0_0 = ind_0.astype(np.integer)\n",
        "    x1_0 = ind_1.astype(np.integer)\n",
        "    x0_1 = x0_0 + 1\n",
        "    x1_1 = x1_0 + 1\n",
        "\n",
        "    # Check if inds are beyond array boundary:\n",
        "    if boundary_correction:\n",
        "        # put all samples outside datacube to 0\n",
        "        inds_out_of_range = (x0_0 < 0) | (x0_1 < 0) | (x1_0 < 0) | (x1_1 < 0) | \\\n",
        "                            (x0_0 >= N0) | (x0_1 >= N0) | (x1_0 >= N1) | (x1_1 >= N1)\n",
        "\n",
        "        x0_0[inds_out_of_range] = 0\n",
        "        x1_0[inds_out_of_range] = 0\n",
        "        x0_1[inds_out_of_range] = 0\n",
        "        x1_1[inds_out_of_range] = 0\n",
        "\n",
        "    w0 = ind_0 - x0_0\n",
        "    w1 = ind_1 - x1_0\n",
        "    # Replace by this...\n",
        "    # input_array.take(np.array([x0_0, x1_0, x2_0]))\n",
        "    output = (input_array[x0_0, x1_0] * (1 - w0) * (1 - w1) +\n",
        "              input_array[x0_1, x1_0] * w0 * (1 - w1) +\n",
        "              input_array[x0_0, x1_1] * (1 - w0) * w1 +\n",
        "              input_array[x0_1, x1_1] * w0 * w1)\n",
        "\n",
        "    if boundary_correction:\n",
        "        output[inds_out_of_range] = 0\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def loadMnistRot():\n",
        "    def load_and_make_list(mode):\n",
        "        data = np.load('mnist_rot/' + mode + '_data.npy')\n",
        "        lbls = np.load('mnist_rot/' + mode + '_label.npy')\n",
        "        data = np.split(data, data.shape[2], 2)\n",
        "        lbls = np.split(lbls, lbls.shape[0], 0)\n",
        "\n",
        "        return list(zip(data, lbls))\n",
        "\n",
        "    train = load_and_make_list('train')\n",
        "    val = load_and_make_list('val')\n",
        "    test = load_and_make_list('test')\n",
        "    return train, val, test\n",
        "\n",
        "\n",
        "def random_rotation(data):\n",
        "    rot = np.random.rand() * 360  # Random rotation\n",
        "    grid = getGrid([28, 28])\n",
        "    grid = rotate_grid_2D(grid, rot)\n",
        "    grid += 13.5\n",
        "    data = linear_interpolation_2D(data, grid)\n",
        "    data = np.reshape(data, [28, 28])\n",
        "    data = data / float(np.max(data))\n",
        "    return data.astype('float32')\n",
        "\n",
        "print('mnist.py is ok!!!')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-08T03:47:04.545804Z",
          "iopub.execute_input": "2022-05-08T03:47:04.546103Z",
          "iopub.status.idle": "2022-05-08T03:47:04.637584Z",
          "shell.execute_reply.started": "2022-05-08T03:47:04.546077Z",
          "shell.execute_reply": "2022-05-08T03:47:04.63687Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "500zTVMaN7Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download_mnist.py"
      ],
      "metadata": {
        "id": "QFPE0n3dN7An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasetType = \"FashionMNIST\" #  FashionMNIST or MNIST\n",
        "saveDir = \"\"\n",
        "# datasetType = 'w'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-08T03:47:04.638726Z",
          "iopub.execute_input": "2022-05-08T03:47:04.63892Z",
          "iopub.status.idle": "2022-05-08T03:47:04.643091Z",
          "shell.execute_reply.started": "2022-05-08T03:47:04.638895Z",
          "shell.execute_reply": "2022-05-08T03:47:04.64206Z"
        },
        "trusted": true,
        "id": "n2SqD_-3N7An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "from imageio import imsave\n",
        "\n",
        "\"\"\"\n",
        "From:\n",
        "https://gist.github.com/ischlag/41d15424e7989b936c1609b53edd1390\n",
        "\"\"\"\n",
        "\n",
        "import gzip\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from six.moves import urllib\n",
        "from six.moves import xrange    # pylint: disable=redefined-builtin\n",
        "# from scipy.misc import imsave\n",
        "# import tensorflow as tf\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'\n",
        "WORK_DIRECTORY = 'raw_data'\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CHANNELS = 1\n",
        "PIXEL_DEPTH = 255\n",
        "NUM_LABELS = 10\n",
        "\n",
        "# def maybe_download(filename):\n",
        "#     \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
        "#     if not tf.gfile.Exists(WORK_DIRECTORY):\n",
        "#         tf.gfile.MakeDirs(WORK_DIRECTORY)\n",
        "#     filepath = os.path.join(WORK_DIRECTORY, filename)\n",
        "#     if not tf.gfile.Exists(filepath):\n",
        "#         filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
        "#         with tf.gfile.GFile(filepath) as f:\n",
        "#             size = f.size()\n",
        "#         print('Successfully downloaded', filename, size, 'bytes.')\n",
        "#     return filepath\n",
        "def download_mnist(data_location, datasetType=\"MNIST\") -> \"None\":\n",
        "    \"\"\"Download the MNIST dataset and then load it into memory.\n",
        "\n",
        "    Defined in :numref:`sec_mnist`\"\"\"\n",
        "\n",
        "    if not os.path.exists(data_location):\n",
        "        os.makedirs(data_location)\n",
        "    # FashionMNIST\n",
        "    if datasetType == \"MNIST\":\n",
        "        mnist_train = torchvision.datasets.MNIST(\n",
        "            root=data_location, train=True, download=True)\n",
        "        mnist_test = torchvision.datasets.MNIST(\n",
        "            root=data_location, train=False, download=True)\n",
        "        path = data_location + \"/MNIST/raw/\"\n",
        "        print(f\"MNIST datasets locate in '{path}'\")\n",
        "    elif datasetType == \"FashionMNIST\":\n",
        "        mnist_train = torchvision.datasets.FashionMNIST(\n",
        "            root=data_location, train=True, download=True)\n",
        "        mnist_test = torchvision.datasets.FashionMNIST(\n",
        "            root=data_location, train=False, download=True)\n",
        "        path = data_location + \"/FashionMNIST/raw/\"\n",
        "        print(f\"FashionMNIST datasets locate in '{path}'\")\n",
        "    else:\n",
        "        raise ValueError(\"datasetType is error!!!\")\n",
        "    # for i in os.listdir(data_location + \"/MNIST/raw/\"):\n",
        "    #     if i[-3:] != '.gz':\n",
        "    #         print(path + i)\n",
        "    return mnist_train, mnist_test\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_location = \"./data/\"\n",
        "    mnistTrain, mnistTest = download_mnist(data_location, datasetType=datasetType)\n",
        "\n",
        "    train_data = np.array(mnistTrain.data.reshape(*(list(mnistTrain.data.shape)), 1))\n",
        "    test_data = np.array(mnistTest.data.reshape(*(list(mnistTest.data.shape)), 1))\n",
        "    train_labels = np.array(mnistTrain.targets)\n",
        "    test_labels = np.array(mnistTest.targets)\n",
        "    print(test_labels)\n",
        "#     这里是原来在project中判断是否在正确的路径，这里由于是用jupyter notebook编写的代码，所以无需判断\n",
        "#     if 'mnist' not in os.getcwd():\n",
        "#         print('Path Error!')\n",
        "#         raise ValueError\n",
        "    if not os.path.isdir(\"./train-images\"):\n",
        "        os.makedirs(\"./train-images\")\n",
        "    if not os.path.isdir(\"./test-images\"):\n",
        "        os.makedirs(\"./test-images\")\n",
        "\n",
        "    # process train data\n",
        "    with open(\"./train-labels.csv\", 'w', newline='') as csvFile:\n",
        "        writer = csv.writer(csvFile, delimiter=',', quotechar='\"')\n",
        "        for i in range(len(train_data)):\n",
        "            imsave(\"./train-images/\" + str(i) + \".jpg\", train_data[i][:, :, 0])\n",
        "            writer.writerow([\"train-images/\" + str(i) + \".jpg\", train_labels[i]])\n",
        "        print(\"train-labels.csv OK !!!\")\n",
        "            \n",
        "    # repeat for test data\n",
        "    with open(\"./test-labels.csv\", 'w', newline='') as csvFile:\n",
        "        writer = csv.writer(csvFile, delimiter=',', quotechar='\"')\n",
        "        for i in range(len(test_data)):\n",
        "            imsave(\"./test-images/\" + str(i) + \".jpg\", test_data[i][:, :, 0])\n",
        "            writer.writerow([\"test-images/\" + str(i) + \".jpg\", test_labels[i]])\n",
        "        print('test-labels.csv OK !!!')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-08T03:47:04.645846Z",
          "iopub.execute_input": "2022-05-08T03:47:04.646346Z",
          "iopub.status.idle": "2022-05-08T03:47:35.426365Z",
          "shell.execute_reply.started": "2022-05-08T03:47:04.646307Z",
          "shell.execute_reply": "2022-05-08T03:47:35.425448Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "wYLzNbQ_N7Ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make_mnist-rot.py "
      ],
      "metadata": {
        "id": "hEJ2mfCGN7Ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# from mnist import random_rotation, loadMnist\n",
        "\n",
        "\n",
        "def makeMnistRot():\n",
        "    \"\"\"\n",
        "    Make MNIST-rot from MNIST\n",
        "    Select all training and test samples from MNIST and select 10000 for train,\n",
        "    2000 for val and 50000 for test. Apply a random rotation to each image.\n",
        "\n",
        "    Store in numpy file for fast reading\n",
        "\n",
        "    \"\"\"\n",
        "    np.random.seed(0)\n",
        "    \n",
        "    #Get all samples\n",
        "    all_samples = loadMnist('train') + loadMnist('test')\n",
        "\n",
        "    #Empty arrays\n",
        "    train_data = np.zeros([28,28,10000])\n",
        "    train_label = np.zeros([10000])\n",
        "    val_data = np.zeros([28,28,2000])\n",
        "    val_label = np.zeros([2000])\n",
        "    test_data = np.zeros([28,28,50000])\n",
        "    test_label = np.zeros([50000])\n",
        "\n",
        "    #new Empty arrays\n",
        "    new_train_data = np.zeros([10000, 28,28])\n",
        "    new_val_data = np.zeros([2000, 28,28])\n",
        "    new_test_data = np.zeros([50000, 28,28])\n",
        "\n",
        "    i = 0\n",
        "    for j in range(10000):\n",
        "        sample =all_samples[i]\n",
        "        train_data[:, :, j] =  random_rotation(sample[0])\n",
        "        new_train_data[j, :, :] =  train_data[:, :, j]\n",
        "        train_label[j] = sample[1]\n",
        "        i += 1\n",
        "\n",
        "    for j in range(2000):\n",
        "        sample = all_samples[i]\n",
        "        val_data[:, :, j] = random_rotation(sample[0])\n",
        "        new_val_data[j, :, :] = val_data[:, :, j]\n",
        "        val_label[j] = sample[1]\n",
        "        i += 1\n",
        "\n",
        "    for j in range(50000):\n",
        "        sample = all_samples[i]\n",
        "        test_data[:, :, j] = random_rotation(sample[0])\n",
        "        new_test_data[j, :, :] = test_data[:, :, j]\n",
        "        test_label[j] = sample[1]\n",
        "        i += 1\n",
        "    if datasetType == \"FashionMNIST\":\n",
        "        saveDir = \"fashionmnist_rotation_new\"\n",
        "    else:\n",
        "        saveDir = \"mnist_rotation_new\"\n",
        "    if not os.path.exists(saveDir):\n",
        "        os.mkdir(saveDir)\n",
        "    new_train = np.hstack((new_train_data.reshape(10000, -1), train_label.reshape(10000, 1)))\n",
        "    new_val = np.hstack((new_val_data.reshape(2000, -1), val_label.reshape(2000, 1)))\n",
        "    new_train_val = np.vstack((new_train, new_val))\n",
        "    new_test = np.hstack((new_test_data.reshape(50000, -1), test_label.reshape(50000, 1)))\n",
        "    print(f\"trainslation finished: train_val_shape={new_train_val.shape}, test_shape={new_test.shape}\")\n",
        "    new_train_file_name = saveDir + '/mnist_all_rotation_normalized_float_train_valid.amat'\n",
        "    new_test_file_name = saveDir + '/mnist_all_rotation_normalized_float_test.amat'\n",
        "    np.savetxt(new_train_file_name, new_train_val, fmt=\"%.6f\")\n",
        "    print(f\"save the {new_train_file_name} finished...\\nlocate in {os.getcwd() + '/' + new_train_file_name}\")\n",
        "    np.savetxt(new_test_file_name, new_test, fmt=\"%.6f\")\n",
        "    print(f\"save the {new_test_file_name} finished...\\nlocate in {os.getcwd() + '/' + new_test_file_name}\")\n",
        "\n",
        "    try:\n",
        "        os.mkdir('mnist_rot/')\n",
        "    except:\n",
        "        None\n",
        "\n",
        "    np.save('mnist_rot/train_data',train_data)\n",
        "    np.save('mnist_rot/train_label', train_label)\n",
        "    np.save('mnist_rot/val_data', val_data)\n",
        "    np.save('mnist_rot/val_label', val_label)\n",
        "    np.save('mnist_rot/test_data', test_data)\n",
        "    np.save('mnist_rot/test_label', test_label)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    makeMnistRot()\n",
        "#     # test new_MNIST_rotation\n",
        "#     train_file_name = 'mnist_rotation_new/mnist_all_rotation_normalized_float_train_valid.amat'\n",
        "#     test_file_name = 'mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat'\n",
        "#     import numpy as np\n",
        "#     with open(train_file_name) as data_file:\n",
        "#         data = np.loadtxt(data_file)\n",
        "#     data.shape\n",
        "#     plt.imshow(data[0][:-1].reshape(28, -1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-08T03:47:35.427736Z",
          "iopub.execute_input": "2022-05-08T03:47:35.427945Z",
          "iopub.status.idle": "2022-05-08T03:49:02.590184Z",
          "shell.execute_reply.started": "2022-05-08T03:47:35.427919Z",
          "shell.execute_reply": "2022-05-08T03:49:02.589214Z"
        },
        "trusted": true,
        "id": "SPV8uyxzN7Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        " \n",
        " \n",
        "def zipDir(dirpath, outFullName):\n",
        "    \"\"\"\n",
        "    压缩指定文件夹\n",
        "    :param dirpath: 目标文件夹路径\n",
        "    :param outFullName: 压缩文件保存路径+xxxx.zip\n",
        "    :return: 无\n",
        "    \"\"\"\n",
        "    zip = zipfile.ZipFile(outFullName, \"w\", zipfile.ZIP_DEFLATED)\n",
        "    for path, dirnames, filenames in os.walk(dirpath):\n",
        "        # 去掉目标跟路径，只对目标文件夹下边的文件及文件夹进行压缩\n",
        "        fpath = path.replace(dirpath, '')\n",
        " \n",
        "        for filename in filenames:\n",
        "            zip.write(os.path.join(path, filename), os.path.join(fpath, filename))\n",
        "    zip.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-08T03:49:02.599172Z",
          "iopub.execute_input": "2022-05-08T03:49:02.599799Z",
          "iopub.status.idle": "2022-05-08T03:49:02.609905Z",
          "shell.execute_reply.started": "2022-05-08T03:49:02.599752Z",
          "shell.execute_reply": "2022-05-08T03:49:02.609045Z"
        },
        "trusted": true,
        "id": "tVOr7o2UN7Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if datasetType == \"FashionMNIST\":\n",
        "        saveDir = \"fashionmnist_rotation_new\"\n",
        "else:\n",
        "    saveDir = \"mnist_rotation_new\"\n",
        "zipDir(saveDir, saveDir + \".zip\")\n",
        "print(f\"zip OK. loacate in {saveDir}.zip\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-08T03:53:55.428991Z",
          "iopub.execute_input": "2022-05-08T03:53:55.429786Z",
          "iopub.status.idle": "2022-05-08T03:54:28.106097Z",
          "shell.execute_reply.started": "2022-05-08T03:53:55.429742Z",
          "shell.execute_reply": "2022-05-08T03:54:28.105274Z"
        },
        "trusted": true,
        "id": "dl0VYsM3N7Aq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}